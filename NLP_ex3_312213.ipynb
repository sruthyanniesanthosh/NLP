{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1c5cv2w2ImO"
   },
   "source": [
    "# Practical exercise 1 - Tokenizing with NLTK/SoMaJo; the distribution of tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjMLbnh61qG4"
   },
   "source": [
    "# 1. Data preparation\n",
    "\n",
    "In this exercise we use a dataset described in the following paper:\n",
    "\n",
    "> Schmidt, T., Hartl, P., Ramsauer, D., Fischer, T., Hilzenthaler, A. & Wolff, C. (2020). Acquisition and Analysis of a Meme Corpus to Investigate Web Culture. In 15th Annual International Conference of the Alliance of Digital Humanities Organizations, DH 2020, Conference Abstracts. Ottawa, Canada.\n",
    "\n",
    "\n",
    "The dataset can be found on https://github.com/lauchblatt/Memes_DH2020. The following code downloads it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3j0JhDC53tj",
    "outputId": "64a7350c-c554-469c-d0a5-270cb1dd1b9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 6906 meme texts; 585405 characters in total\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import urllib.request\n",
    "\n",
    "data_url = 'https://raw.githubusercontent.com/lauchblatt/Memes_DH2020/main/Meme_Corpus%20-%20memes.csv'\n",
    "\n",
    "texts = []\n",
    "with urllib.request.urlopen(data_url) as csvfile:\n",
    "    reader = csv.DictReader(codecs.iterdecode(csvfile, 'utf-8'))\n",
    "    for row in reader:\n",
    "        texts.append(row['text'])\n",
    "\n",
    "# remove memes without text\n",
    "texts = [text for text in texts if text!=\"NA\" and text.strip()]\n",
    "\n",
    "print(f'read {len(texts)} meme texts; {sum([len(text) for text in texts])} characters in total')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFq3un66D_lY"
   },
   "source": [
    "Let us look at a few entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVCK2k4mDhoB",
    "outputId": "9aa17edf-4833-4f6c-da9d-711c9504e64e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo dawg we heard yo like multilasers so\n",
      "we put multilasers on yo multilasers so\n",
      "you can fire your multilasers while you fire\n",
      "your multilasers!!!!\n",
      "\n",
      "###\n",
      "mainf.cpp\n",
      "50 DALl5 HEARD SOU LKE\n",
      "OnPuTING.\n",
      "#include\n",
      "<iostream>\n",
      "#include <stdlib.h>\n",
      "using namespace std;\n",
      "int factorial(int i)\n",
      "if (1-0) return 1;\n",
      "if (i>0) return i*factorial(i-1)\n",
      "SO IPUTA FUNCTION SOUR FUNETION\n",
      "SO YOU CRN CORPUTE邑HILE yUU CORPUTE.\n",
      "Wİ\n",
      "\n",
      "###\n",
      "F SEEN C\n",
      "\n",
      "###\n",
      "YO DAWG\n",
      "SO I HEARD YOU LIKE\n",
      "VIDEO GAMES\n",
      "GAME\n",
      "Ou\n",
      "陳\n",
      ".\n",
      "12\n",
      "3\n",
      "\n",
      "###\n",
      "BABY S\n",
      "FRST\n",
      "IS PREGNANT\n",
      "TOO!\n",
      "\n",
      "###\n",
      "LOOONG\n",
      "Click to View\n",
      "\n",
      "###\n",
      "YO DAWG WE HERD YOU LIKE ARROWS SO WE PUT AN ARROW IN YO KNEE SO\n",
      "YOU CAN STOP BEING AND ADVENTURER WHILE U STOP ADVENTURING\n",
      "\n",
      "###\n",
      "Why Kzibit says \"yo dawg\"\n",
      "ALIENSH\n",
      "HD\n",
      "HISTORY.COM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n###\\n'.join(texts[4022:4030]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJx5aDt-5f5c"
   },
   "source": [
    "Note: this is very strange data but should suffice for this exercise!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmpxRhaV_D2b"
   },
   "source": [
    "# 2. Data processing\n",
    "\n",
    "## Tokenizing with SoMaJo\n",
    "\n",
    "We can assume that every meme consists of one \"sentence\". To further split these into single words we have to tokenize the data.\n",
    "\n",
    "We can use the SoMaJo tokenizer which was developed especially for social media data and is easy to use.\n",
    "\n",
    "https://github.com/tsproisl/SoMaJo\n",
    "\n",
    "more info on the system: https://www.aclweb.org/anthology/W16-2607.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w5I-4DPBc4k",
    "outputId": "88de9a6c-36bf-4d09-b3e3-80b4901c434f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SoMaJo\n",
      "  Downloading SoMaJo-2.2.1-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.5/90.5 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex>=2019.02.18 in /opt/anaconda3/lib/python3.8/site-packages (from SoMaJo) (2022.3.15)\n",
      "Installing collected packages: SoMaJo\n",
      "Successfully installed SoMaJo-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install SoMaJo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V2ICBAIdBo9l"
   },
   "outputs": [],
   "source": [
    "from somajo import SoMaJo\n",
    "\n",
    "somajo_tokenizer = SoMaJo(language=\"en_PTB\",\n",
    "                          split_camel_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "E-45d8AcCM9l"
   },
   "outputs": [],
   "source": [
    "data_tok = []\n",
    "for sentence in somajo_tokenizer.tokenize_text(texts):\n",
    "    data_tok.append([token.text for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykl-epPuEU5T",
    "outputId": "6df57d88-2a0f-4b0f-f820-6f44cfbbe725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAUI']\n",
      "['Hot', 'Berks', '524', '755', 'Berks', '1084', '1266', '182', 'ratio', 'of', 'diff', '0.787878788', '0.9', '0.8', '0.7', '0.6', '0.5', 'Nostril', '(', 'L', ')', 'Nostril', '(', 'R', ')', '1127', '565', '697', '132', 'ratio', 'of', 'diff', 'y', '-0', '.', '0133x', '0.7671', 'R2', '0.2015', 'diff', '93', '0.704545455', 'Mouth', '(', 'L', 'Mouth', '(', 'Ri', ')', '546', '720', '174', '1110', 'Seriesi', 'Linear', '(', 'Series1', ')', '1235', 'ratio', 'of', 'diff', 'diff', '0.718390805', '0.3', '0.2', '0.1', 'Chin', 'forehead', '669', '39', '630', '568', '83', 'ratio', 'of', 'diff', 'clifi', '0.76984127', '4', '6', '8', '10', 'Mandible', '(', 'L', ')', 'Mandible', '(', 'Ri', '409', '1023', '1339', '316', 'ratio', 'of', 'diff', '0.718181818', '849', 'cliff', 'CONCLUSION', ':', 'PLAUSIBLE', 'Nose', '(', 'Top', ')', '288', '285', '368', '83', 'ratio', 'of', 'diff', '0.546052632', 'Nose', '(', 'Bottom', 'diff', '152', 'Eye', 'Width', '(', 'L', ')', 'X1', 'X2', 'NEA', '572', '98', '474', '1056', '1125', '69', 'ratio', 'of', 'diff', 'clifi', '0.704081633', 'Eye', 'Width', 'X1', 'X2', '(', 'R', ')', '707', '814', '107', '1230', '1306', '76', 'ratio', 'of', 'diff', '0.710280374', 'clifi']\n",
      "['ERMAHGERD', 'M', 'HOT', '.']\n",
      "['GERSBERMS', 'MAH', 'FRAVRIT', 'BERKS']\n",
      "['ERMAHGERD', 'MILK', 'BONE', 'MERLKBEHRNS', 'LARGE']\n",
      "['ERMAHGERD', 'S', 'K', 'LERNERD', 'SKERNERD']\n"
     ]
    }
   ],
   "source": [
    "print(data_tok[0])\n",
    "print(data_tok[1])\n",
    "print(data_tok[2])\n",
    "print(data_tok[3])\n",
    "print(data_tok[4])\n",
    "print(data_tok[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wtv3RZCw7MV5"
   },
   "source": [
    "## Further data processing\n",
    "\n",
    "For this kind of data, lower-casing everything seems to make sense. In general: this process deletes information and also sometimes meaning; e.g. Apple (company) and apple (fruit) can not be destinguished if we ignore case. However, generalization increases. Thus, you should take this decision conciously and be aware of its effects! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oaiZupzmHS4b"
   },
   "outputs": [],
   "source": [
    "data_tok = [[token.lower() for token in sentence] for sentence in data_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36ohZEZr9CDr",
    "outputId": "bf4ba516-f858-4373-d3de-c423ca9801c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['maui']\n",
      "['hot', 'berks', '524', '755', 'berks', '1084', '1266', '182', 'ratio', 'of', 'diff', '0.787878788', '0.9', '0.8', '0.7', '0.6', '0.5', 'nostril', '(', 'l', ')', 'nostril', '(', 'r', ')', '1127', '565', '697', '132', 'ratio', 'of', 'diff', 'y', '-0', '.', '0133x', '0.7671', 'r2', '0.2015', 'diff', '93', '0.704545455', 'mouth', '(', 'l', 'mouth', '(', 'ri', ')', '546', '720', '174', '1110', 'seriesi', 'linear', '(', 'series1', ')', '1235', 'ratio', 'of', 'diff', 'diff', '0.718390805', '0.3', '0.2', '0.1', 'chin', 'forehead', '669', '39', '630', '568', '83', 'ratio', 'of', 'diff', 'clifi', '0.76984127', '4', '6', '8', '10', 'mandible', '(', 'l', ')', 'mandible', '(', 'ri', '409', '1023', '1339', '316', 'ratio', 'of', 'diff', '0.718181818', '849', 'cliff', 'conclusion', ':', 'plausible', 'nose', '(', 'top', ')', '288', '285', '368', '83', 'ratio', 'of', 'diff', '0.546052632', 'nose', '(', 'bottom', 'diff', '152', 'eye', 'width', '(', 'l', ')', 'x1', 'x2', 'nea', '572', '98', '474', '1056', '1125', '69', 'ratio', 'of', 'diff', 'clifi', '0.704081633', 'eye', 'width', 'x1', 'x2', '(', 'r', ')', '707', '814', '107', '1230', '1306', '76', 'ratio', 'of', 'diff', '0.710280374', 'clifi']\n",
      "['ermahgerd', 'm', 'hot', '.']\n",
      "['gersberms', 'mah', 'fravrit', 'berks']\n",
      "['ermahgerd', 'milk', 'bone', 'merlkbehrns', 'large']\n",
      "['ermahgerd', 's', 'k', 'lernerd', 'skernerd']\n"
     ]
    }
   ],
   "source": [
    "print(data_tok[0])\n",
    "print(data_tok[1])\n",
    "print(data_tok[2])\n",
    "print(data_tok[3])\n",
    "print(data_tok[4])\n",
    "print(data_tok[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc74x-tZ_LH0"
   },
   "source": [
    "# 3. Corpus statistics\n",
    "\n",
    "We will use the term \"frequency\" of a word type to express the absolute number of times this word occurs (in any context) in our corpus.\n",
    "\n",
    "Please note the terminological distinction:<br>\n",
    "**token**: Word form occuring in a text. The sentence \"This is it, is it?\" has 7 tokens \\['This', 'is', 'it', ',', 'is', 'it', '?'\\].<br>\n",
    "**type**: Unique word form in a text. The sentence \"This is it, is it?\" has 5 types {',', '?', 'This', 'is', 'it'}<br>\n",
    "A language/vocabulary consists of several word types; a corpus consists of tokens (which are mentions/occurrences of these types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "PFfJ4gYWL6Qs"
   },
   "outputs": [],
   "source": [
    "# count words and their frequencies\n",
    "from collections import Counter\n",
    "\n",
    "sentences = data_tok\n",
    "\n",
    "words = Counter(word for sentence in sentences for word in sentence)\n",
    "# Note: \"words\" now contains a mapping of words to their frequencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4yNUCGoQMFIH",
    "outputId": "efe5de34-940b-4f81-a168-49479e392a95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of types (unique words): 20152\n",
      "Total number of tokens: 112846\n",
      "Number of types with frequency of occurrence 1: 12674\n",
      "Frequency of token \"manter\": 1\n",
      "Frequency of token \"woman\": 34\n",
      "Frequency of token \"computing\": 0\n",
      "Frequency of token \"meaning\": 14\n",
      "Frequency of token \"!\": 704\n",
      "Frequency of token \"?\": 1060\n"
     ]
    }
   ],
   "source": [
    "# total number of types in the corpus\n",
    "print(f'Total number of types (unique words): {len(words)}')\n",
    "\n",
    "# total number of tokens in the corpus\n",
    "print(f'Total number of tokens: {sum(words.values())}')\n",
    "\n",
    "# how many words occur only once?\n",
    "print(f'Number of types with frequency of occurrence 1: {len([True for word in words if words[word] == 1])}')\n",
    "\n",
    "# show the frequency of some words\n",
    "for word in ('manter', 'woman', 'computing', 'meaning', '!', '?'):\n",
    "    print(f'Frequency of token \"{word}\": {words[word]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHyrQuM5Mnoz",
    "outputId": "a938036c-7d4d-429f-f28b-39c3eb7c635d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most frequent words:\n",
      "['the', ',', 'you', '.', 'a', 'to', 'i', 'of', 'in', '?', 'and', 'is', 'so', 'my', 'it', 'like', 'yo', 'your', '!', 'that']\n",
      "\n",
      "some infrequent words:\n",
      "['prョ', 'bigbag', 'ouu', 'favre', 'webb', 'basetgod', 'asedegod', 'lurkda', 'ank', 'manter']\n"
     ]
    }
   ],
   "source": [
    "sorted_words = sorted(words, key=lambda word: words[word], reverse=True)\n",
    "\n",
    "print('the most frequent words:')\n",
    "print(sorted_words[:20])\n",
    "\n",
    "print('\\nsome infrequent words:')\n",
    "print(sorted_words[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "CPgFbGDGQbBi"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "### EXERCISE (see tasks at the end of the notebook) ###\n",
    "#######################################################\n",
    "\n",
    "# You should assign each word a rank according to the sorting by its frequency (i.e. the most \n",
    "# frequent word gets rank 1, the 2nd most frequent word gets rank 2, etc.).\n",
    "# The \"ranks\" dictionary should map each word to its frequency rank.\n",
    "ranks = {}\n",
    "i=1\n",
    "for word in sorted_words:\n",
    "    ranks.update({word : i})\n",
    "    i+=1\n",
    "#print(ranks)\n",
    "\n",
    "# Assign each word rank the word frequency (i.e., for example, if the word on rank 10 (= the 10th \n",
    "# most frequent word) occurs 500 times, the resulting dictionary should map 10 to 500.) \n",
    "# The \"frequency_ranks\" dictionary should save a mapping from ranks to frequencies.\n",
    "frequency_ranks = {}\n",
    "j=1\n",
    "for word in sorted_words:\n",
    "    frequency_ranks.update({j:words[word]})\n",
    "    j+=1\n",
    "    \n",
    "#print(frequency_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_pr3Gi8O3qg"
   },
   "source": [
    "# 4. Plotting Word Distribution\n",
    "\n",
    "Zipf's law states that: \\begin{equation}\\textit{occurrence_probability}(\\textit{word}) = \\frac{c}{\\text{rank}(\\textit{word})}\\end{equation}\n",
    "In other words: the occurrence probability of a word is inversely proportional to its frequency rank (with a corpus specific constant c).\n",
    "\n",
    "We can compute the occurrence probability of a word based on corpus data as follows:\n",
    "\\begin{equation}\n",
    "    \\textit{occurrence_probability}(\\textit{word}) = \\frac{\\textit{frequency of occurrence}(\\textit{word})}{\\textit{number of all words}}\n",
    "\\end{equation}\n",
    "For example, when a word occurs 20 times in a corpus of 100 tokens, its occurrence_probability is $0.2$.\n",
    "\n",
    "Above we calculated the frequency of occurrence of each word in our data. We now want to plot this value against the rank using Zipf's law and the formulae above.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\textit{frequency of occurrence}(\\textit{word})}{\\textit{number of all words}} = \\frac{c}{\\text{rank}(\\textit{word})}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\textit{frequency of occurrence}(\\textit{word}) = \\frac{c * \\textit{number of all words}}{\\text{rank}(\\textit{word})}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, if we want to plot the frequency on the y-axis, for any given rank $x$, the plot should display:\n",
    "\\begin{equation}\n",
    "f(x) = y = \\frac{c * \\textit{number of all words}}{x}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "9RAAfh2_O_R_",
    "outputId": "39d9f536-826b-44cb-909b-d4e2d71c72ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set the constant c to some value for now\n",
    "c = 0.03\n",
    "\n",
    "# x-axis range:\n",
    "n_minimum = 1\n",
    "n_limit = 20160\n",
    "\n",
    "# plot Zipf\n",
    "x_zipf = np.array(range(n_minimum, n_limit + 1))\n",
    "y_zipf = c * sum(words.values())/x_zipf  # this is the last formula above\n",
    "plt.plot(x_zipf, y_zipf, label='Zipf')\n",
    "# Note: this is what Zipf's law claims - we did not test it with our data yet.\n",
    "\n",
    "# here we plot the meme data (using the values from the cell above)\n",
    "if frequency_ranks:\n",
    "    lists = sorted(frequency_ranks.items())\n",
    "    x, y = zip(*lists)\n",
    "    plt.plot(x[n_minimum:n_limit], y[n_minimum:n_limit], label='Meme data')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLTI-vUSEE7E"
   },
   "source": [
    "#5. Collocations\n",
    "\n",
    "A collocation is \"a combination of words in a language that happens very often and more frequently than would happen by chance\".<br>\n",
    "These combinations are especially meaningful; there usually is a strong connection between the words; the words in combination often lead a new combined meaning; strong collocations can be considered lexical items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRNa3XLGFkF3"
   },
   "source": [
    "## 5.1 Co-occuring word pairs\n",
    "\n",
    "We only have the frequencies of individual words so far.\n",
    "\n",
    "To compute collocation measure we need frequencies of co-occurring word pairs.\n",
    "\n",
    "For example, the tokenized sentence ['This', 'is', 'it', ',', 'is', 'it', '?']. has the following co-occuring word pairs:\n",
    "- ('This', 'is') frequency 1\n",
    "- ('is', 'it') frequency 2\n",
    "- ('it', ',') frequency 1\n",
    "- (',', 'is') frequency 1\n",
    "- ('it', '?') frequency 1\n",
    "\n",
    "Note that the sentence has 7 tokens, thus, 6 co-occurring word pairs (also known as bigrams), however, one of those occurs twice.\n",
    "\n",
    "We now count these for our entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "B_KZ-Cw2EEJs"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_word_pairs = Counter((word, sentence[index+1])\n",
    "                         for sentence in sentences\n",
    "                         for index, word in enumerate(sentence)\n",
    "                         if index+1 < len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1IjS4NYF5BC",
    "outputId": "798857a8-9891-4f84-e8ca-153b9ae9f517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most frequent word pairs:\n",
      "[(('yo', 'dawg'), 390), (('you', 'like'), 325), (('you', 'can'), 262), (('so', 'we'), 260), (('so', 'you'), 247), ((',', 'i'), 222), (('dat', 'ass'), 216), (('while', 'you'), 201), (('heard', 'you'), 196), (('we', 'put'), 193)]\n",
      "\n",
      "The number of unique word pairs: 64778\n",
      "\n",
      "The number of unique word pairs with a frequency greater than 1:\n",
      "13243\n"
     ]
    }
   ],
   "source": [
    "# let us look at some\n",
    "print('The 10 most frequent word pairs:')\n",
    "print(sorted(all_word_pairs.items(), key=lambda pair: pair[1], reverse=True)[:10])\n",
    "\n",
    "print(f'\\nThe number of unique word pairs: {len(all_word_pairs)}')\n",
    "\n",
    "print('\\nThe number of unique word pairs with a frequency greater than 1:')\n",
    "print(len([pair for pair, frequency in all_word_pairs.items() if frequency > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq_UG2l-G0ds",
    "outputId": "b43a7a63-7d51-4125-d834-ead3663d496d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of remaining word pairs: 1949\n"
     ]
    }
   ],
   "source": [
    "# to make it computationally feasible, only analyze word pairs with freq > some threshold\n",
    "# you might have to increase this value if running the cells in 5.2 take too long to finish\n",
    "threshold = 5\n",
    "word_pairs = {word_pair: frequency for word_pair, frequency in all_word_pairs.items() \n",
    "              if frequency >= threshold}\n",
    "print(f'number of remaining word pairs: {len(word_pairs)}')\n",
    "#word_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJJNyUdMHV9M"
   },
   "source": [
    "## 5.2 Collocation measures\n",
    "\n",
    "Above we actually used the most basic collocation measure: the frequency $o_{11}$ of the co-occurring word pair.\n",
    "\n",
    "Now we will compute the entire contingency table for each of the co-occuring word pairs (this might take a few seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "o_epuAMaHVn9"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "o11 = word_pairs\n",
    "o12 = defaultdict(int)\n",
    "o21 = defaultdict(int)\n",
    "o22 = defaultdict(int)\n",
    "\n",
    "for word_pair in word_pairs:\n",
    "    word1, word2 = word_pair\n",
    "    for other_word_pair in word_pairs:\n",
    "        other_word1, other_word2 = other_word_pair\n",
    "        if word1 == other_word1:\n",
    "            if word2 != other_word2:\n",
    "                o12[word_pair] += word_pairs[other_word_pair]\n",
    "            else:\n",
    "                # we already have this case in word_pairs\n",
    "                pass\n",
    "        else:\n",
    "            if word2 == other_word2:\n",
    "                o21[word_pair] += word_pairs[other_word_pair]\n",
    "            else:\n",
    "                o22[word_pair] += word_pairs[other_word_pair]\n",
    "\n",
    "# set min value to 1\n",
    "for pair in word_pair:\n",
    "    for cell in (o12, o21, o22):\n",
    "        if not cell[word_pair]:\n",
    "            cell[word_pair] = 1\n",
    "\n",
    "contingency_tables = {'o11': o11, 'o12': o12, 'o21': o21, 'o22': o22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jJy5eIfuH1OU"
   },
   "outputs": [],
   "source": [
    "# A function to print highest ranked collocations, using a given collocation measure to compute ranking\n",
    "def print_highest_ranked_collocations(measure, top=10, tables=contingency_tables):\n",
    "    for pair in sorted(tables['o11'], key=lambda word_pair: measure(word_pair, tables), reverse=True)[:top]:\n",
    "        print((pair, tables['o11'][pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvt0uQxgIQlS",
    "outputId": "f62f7b8b-3f91-4d9f-8520-38e166d2b7b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yo', 'dawg'), 390)\n",
      "(('you', 'like'), 325)\n",
      "(('you', 'can'), 262)\n",
      "(('so', 'we'), 260)\n",
      "(('so', 'you'), 247)\n",
      "((',', 'i'), 222)\n",
      "(('dat', 'ass'), 216)\n",
      "(('while', 'you'), 201)\n",
      "(('heard', 'you'), 196)\n",
      "(('we', 'put'), 193)\n",
      "(('in', 'the'), 189)\n",
      "(('of', 'the'), 185)\n",
      "(('put', 'a'), 173)\n",
      "(('i', 'heard'), 148)\n",
      "((',', 'so'), 146)\n",
      "(('dawg', ','), 142)\n",
      "(('i', \"'m\"), 138)\n",
      "(('in', 'your'), 135)\n",
      "(('dawg', 'i'), 135)\n",
      "(('i', 'herd'), 127)\n"
     ]
    }
   ],
   "source": [
    "def frequency(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    return pair_o11\n",
    "\n",
    "print_highest_ranked_collocations(frequency, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJUmsfc9H7gj",
    "outputId": "6b8dcd8f-c063-4208-af64-2013a0c66c0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fall', 'asleep'), 5)\n",
      "(('days', 'later'), 5)\n",
      "(('forever', 'alone'), 5)\n",
      "(('little', 'pony'), 5)\n",
      "(('best', 'friend'), 5)\n",
      "(('birthday', 'party'), 5)\n",
      "(('nice', 'gane'), 5)\n",
      "(('runs', 'marathon'), 5)\n",
      "(('aliensh', 'hd'), 5)\n",
      "(('ze', 'urger.com'), 5)\n",
      "(('tap', '*'), 5)\n",
      "(('onion', 'ring'), 5)\n",
      "(('profile', 'pictures'), 5)\n",
      "(('highest', 'place'), 5)\n",
      "(('something', 'sharp'), 5)\n",
      "(('page', 'contents'), 5)\n",
      "(('contents', 'featured'), 5)\n",
      "(('current', 'events'), 5)\n",
      "(('events', 'random'), 5)\n",
      "(('random', 'article'), 5)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# mutual information\n",
    "def mi(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    return math.log(pair_o11/pair_e11)\n",
    "\n",
    "print_highest_ranked_collocations(mi, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSoa6Rs8-79i"
   },
   "source": [
    "# 6. Exercises\n",
    "\n",
    "1.   Plotting your distribution\n",
    "\n",
    "    1.   Assign each word a rank according to the sorting by its frequency (i.e. the most frequent word gets rank 1, the 2nd most frequent word gets rank 2, etc.).\n",
    "\n",
    "    2.   Assign each word rank the word frequency (i.e., for example, if the word on rank 10 (= the 10th most frequent word) occurs 500 times, the resulting dictionary should map 10 to 500.) You should save the result in the variable 'frequency_ranks', see above.\n",
    "\n",
    "    3.   Plot your distribution together with Zipf's Law (if you defined the variable 'frequency_ranks' correctly, the code in 4. should do that). Modify the constant 'c' so the Zipf-plot fits to your data (approximately). You might also have to modify n_minimum and n_limit slightly so you can see it better.\n",
    "\n",
    "2.   Collocations\n",
    "\n",
    "    1.   Compare the number of unique word pairs to the number of unique words in our data. What do you observe? Is this expected? Why?\n",
    "    2.   Would you expect the distribution of unique word pairs also to follow Zipf’s law? Why (not)?\n",
    "    3.   Look at the top results extracted using the frequency measure. Do you think the definition of a collocation holds for these word pairs? Are these really collocations? Why (not)? What are issues when using just the frequency of word pairs as collocation measure?\n",
    "    4.   **(This is the main task of this exercise!)** Familiarize yourself with the language in this meme dataset. Write down 10 collocations for this data, i.e. pairs of words which you think are very strongly connected here (they do not really occur in other context and have a special meaning together). Implement a few (at least 5 in total) other collocation measures (http://collocations.de/AM/index.html). Which of these measures predicts the most of your 10 collocations in its top 100 results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTzvpnPA_C5S"
   },
   "source": [
    "## Answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1A - Assign each word a rank according to its frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The \"ranks\" dictionary  map each word to its frequency rank.\n",
    "ranks = {}\n",
    "i=1\n",
    "for word in sorted_words: #sorted words contain all the words sorted by its frequency\n",
    "    ranks.update({word : i})\n",
    "    i+=1\n",
    "#print(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1B - Assign each word rank , the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"frequency_ranks\" dictionary  save a mapping from ranks to frequencies.\n",
    "frequency_ranks = {}\n",
    "j=1\n",
    "\n",
    "#taking the frequency of words from words dict, using the sorted order\n",
    "for word in sorted_words:\n",
    "    frequency_ranks.update({j:words[word]})\n",
    "    j+=1\n",
    "    \n",
    "#print(frequency_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1C - Plotting distribution together with Zipf's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set the constant c to value which fits the lines\n",
    "c = 0.035\n",
    "\n",
    "# x-axis range:\n",
    "n_minimum = 1\n",
    "n_limit = 20160\n",
    "\n",
    "# plot Zipf\n",
    "x_zipf = np.array(range(n_minimum, n_limit + 1))\n",
    "y_zipf = c * sum(words.values())/x_zipf  # this is the last formula above\n",
    "plt.plot(x_zipf, y_zipf, label='Zipf')\n",
    "# Note: this is what Zipf's law claims - we did not test it with our data yet.\n",
    "\n",
    "# here we plot the meme data (using the values from the cell above)\n",
    "if frequency_ranks:\n",
    "    lists = sorted(frequency_ranks.items())\n",
    "    x, y = zip(*lists)\n",
    "    plt.plot(x[n_minimum:n_limit], y[n_minimum:n_limit], label='Meme data')\n",
    "\n",
    "plt.xlabel(\"rank of words\")\n",
    "plt.ylabel(\"frequency of words\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the orange line fits with the blue line for c =0.035. We see that the rank 1 has freq< 5000. \n",
    "\n",
    "Hence Zipf's law holds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A -  Comparison of number of unique word pairs and number of unique words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of unique word pairs: 64778\n",
      "Total number of types (unique words): 20152\n"
     ]
    }
   ],
   "source": [
    "print(f'\\nThe number of unique word pairs: {len(all_word_pairs)}')\n",
    "print(f'Total number of types (unique words): {len(words)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the number unique word pairs is three times the number of unique words. This is an expected scenario as the number of unique word pairs will be greater than the number of words. Many unique combinations are possible. The total unique pairs possible from 20152 words are 203041476."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B - Does the unique word pairs follow Zipf's law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the unique word pairs will also follow Zipf's law. The number of word pair with higher frequency will be less.\n",
    "\n",
    "Reference paper: https://aclanthology.org/C02-1117.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2C - Issues of using frequency as Collocation measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collocation definition does not hold for the word pairs extracted using frequency measure. These word pairs are not meaningful, i.e, does not make a useful phrase. Hence they are not really collocation. They are just words which were adjacent to each other many times. Thus it doesnot contribute to the meaning or have contextual properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D - Implementing 5 collocation measures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten meaningful collolaction are - \n",
    "('fall', 'asleep')\n",
    "('days', 'later')\n",
    "('forever', 'alone')\n",
    "('little', 'pony')\n",
    "('best', 'friend')\n",
    "('birthday', 'party')\n",
    "('justin', 'bieber')\n",
    "('hours', 'ago')\n",
    "('runs', 'marathon')\n",
    "('ice', 'cream')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yo', 'dawg'), 390)\n",
      "(('dat', 'ass'), 216)\n",
      "(('so', 'we'), 260)\n",
      "(('we', 'put'), 193)\n",
      "(('you', 'like'), 325)\n",
      "(('you', 'can'), 262)\n",
      "(('.', 'ne'), 108)\n",
      "(('hours', 'ago'), 90)\n",
      "(('based', 'god'), 74)\n",
      "(('heard', 'you'), 196)\n",
      "(('while', 'you'), 201)\n",
      "(('put', 'a'), 173)\n",
      "(('do', \"n't\"), 125)\n",
      "(('i', \"'m\"), 138)\n",
      "(('memegenerator', '.'), 97)\n",
      "(('i', 'heard'), 148)\n",
      "(('dawg', ','), 142)\n",
      "(('i', 'herd'), 127)\n",
      "(('grumpy', 'cat'), 45)\n",
      "(('minutes', 'ago'), 54)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "def poisson(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    x =  math.log(pair_o11) - math.log(pair_e11) - 1\n",
    "    return pair_o11*x\n",
    "\n",
    "print_highest_ranked_collocations(poisson, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fravrit', 'berks'), 7)\n",
      "(('cheez', 'burger'), 9)\n",
      "(('justin', 'bieber'), 12)\n",
      "(('scumbag', 'steve'), 16)\n",
      "(('fall', 'asleep'), 5)\n",
      "(('blake', 'boston'), 10)\n",
      "(('juliana', 'tamara'), 8)\n",
      "(('days', 'later'), 5)\n",
      "(('ice', 'cream'), 6)\n",
      "(('forever', 'alone'), 5)\n",
      "(('little', 'pony'), 5)\n",
      "(('best', 'friend'), 5)\n",
      "(('birthday', 'party'), 5)\n",
      "(('hide', 'report'), 7)\n",
      "(('nice', 'gane'), 5)\n",
      "(('runs', 'marathon'), 5)\n",
      "(('ridiculously', 'photogenic'), 15)\n",
      "(('anonymous', '08/18/11'), 8)\n",
      "(('tide', 'goes'), 10)\n",
      "(('neil', 'armstrong'), 6)\n"
     ]
    }
   ],
   "source": [
    "def dice(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    x =  pair_R1 + pair_C1\n",
    "    return 2*pair_o11 / x\n",
    "\n",
    "print_highest_ranked_collocations(dice, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('blake', 'boston'), 10)\n",
      "(('tide', 'goes'), 10)\n",
      "(('28', '29'), 10)\n",
      "(('29', '30'), 10)\n",
      "(('cheez', 'burger'), 9)\n",
      "(('cutie', 'mark'), 9)\n",
      "(('19', '20'), 13)\n",
      "(('fanny', 'fanny'), 14)\n",
      "(('justin', 'bieber'), 12)\n",
      "(('fall', 'asleep'), 5)\n",
      "(('juliana', 'tamara'), 8)\n",
      "(('days', 'later'), 5)\n",
      "(('ice', 'cream'), 6)\n",
      "(('forever', 'alone'), 5)\n",
      "(('little', 'pony'), 5)\n",
      "(('best', 'friend'), 5)\n",
      "(('birthday', 'party'), 5)\n",
      "(('nice', 'gane'), 5)\n",
      "(('runs', 'marathon'), 5)\n",
      "(('ridiculously', 'photogenic'), 15)\n"
     ]
    }
   ],
   "source": [
    "def chi_squared(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_R2 = pair_o21 + pair_o22\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_C2 = pair_o12 + pair_o22\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    pair_e22 = pair_R2 * pair_C2 / float(pair_N)\n",
    "    \n",
    "    \n",
    "    x =  pow((pair_o11 - pair_e11),2)*pair_N\n",
    "    return x/( pair_e11*pair_e22)\n",
    "\n",
    "print_highest_ranked_collocations(chi_squared, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yo', 'dawg'), 390)\n",
      "(('dat', 'ass'), 216)\n",
      "(('we', 'put'), 193)\n",
      "(('so', 'we'), 260)\n",
      "(('based', 'god'), 74)\n",
      "(('hours', 'ago'), 90)\n",
      "(('you', 'like'), 325)\n",
      "(('.', 'ne'), 108)\n",
      "(('you', 'can'), 262)\n",
      "(('grumpy', 'cat'), 45)\n",
      "(('big', 'chungus'), 37)\n",
      "(('portable', 'atrocities'), 30)\n",
      "(('encapsulated', 'en'), 24)\n",
      "(('heard', 'you'), 196)\n",
      "(('has', 'cheezburger'), 49)\n",
      "(('while', 'you'), 201)\n",
      "(('minutes', 'ago'), 54)\n",
      "(('put', 'a'), 173)\n",
      "(('do', \"n't\"), 125)\n",
      "(('scumbag', 'steve'), 16)\n"
     ]
    }
   ],
   "source": [
    "def mi3(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    x =  pow(pair_o11,3)/pair_e11\n",
    "    return math.log(x)\n",
    "\n",
    "print_highest_ranked_collocations(mi3, top=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fravrit', 'berks'), 7)\n",
      "(('cheez', 'burger'), 9)\n",
      "(('justin', 'bieber'), 12)\n",
      "(('scumbag', 'steve'), 16)\n",
      "(('fall', 'asleep'), 5)\n",
      "(('blake', 'boston'), 10)\n",
      "(('juliana', 'tamara'), 8)\n",
      "(('days', 'later'), 5)\n",
      "(('ice', 'cream'), 6)\n",
      "(('forever', 'alone'), 5)\n",
      "(('little', 'pony'), 5)\n",
      "(('best', 'friend'), 5)\n",
      "(('birthday', 'party'), 5)\n",
      "(('hide', 'report'), 7)\n",
      "(('nice', 'gane'), 5)\n",
      "(('runs', 'marathon'), 5)\n",
      "(('ridiculously', 'photogenic'), 15)\n",
      "(('anonymous', '08/18/11'), 8)\n",
      "(('tide', 'goes'), 10)\n",
      "(('neil', 'armstrong'), 6)\n"
     ]
    }
   ],
   "source": [
    "def jaccard(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    x =  pair_o11 + pair_o12 + pair_o21\n",
    "    return pair_o11 / x\n",
    "\n",
    "print_highest_ranked_collocations(jaccard, top=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the measures dice and Jaccard produce the most meaningful results in their top 20. Then comes chi_squared and then $mi^3$ and poisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-2022_exercise3_statistics-collocations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
