{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1c5cv2w2ImO"
   },
   "source": [
    "# Practical exercise 1 - Tokenizing with NLTK/SoMaJo; the distribution of tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7fDOZ0o8D6g"
   },
   "source": [
    "# 1. Data preparation (email data)\n",
    "\n",
    "File emails-body.txt.zip - extracted column \"ExtractedBodyText\" from the data set available on kaggle:\n",
    "https://www.kaggle.com/datasets/kaggle/hillary-clinton-emails?select=Emails.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "1GCWW8Ca7uMx",
    "outputId": "5550079a-43aa-402a-ca02-2f1eb15eb927"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1cf71e73-4c5c-467d-8b0e-1f8dad218203\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1cf71e73-4c5c-467d-8b0e-1f8dad218203\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving emails-body.txt.zip to emails-body.txt (1).zip\n"
     ]
    }
   ],
   "source": [
    "# If you are using google colab, you need to upload the files to the environment.\n",
    "# To do this you can use this cell.\n",
    "# If you run the notebook locally, you can ignore this cell.\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "SpTw8IS88DRh"
   },
   "outputs": [],
   "source": [
    "# extract the zip file\n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"emails-body.txt.zip\", 'r') as zip_f:\n",
    "    zip_f.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ra1q2OIs9EGF",
    "outputId": "89051597-f627-4ca4-d859-b5cc60207fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of email bodies: 6741\n"
     ]
    }
   ],
   "source": [
    "# read the file\n",
    "texts = open('emails-body.txt').read().split('<cmail>\\n')\n",
    "print(f'number of email bodies: {len(texts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WODR4cQT9Qs2",
    "outputId": "ee144695-ebd2-423a-967b-0dac8ec4b690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fyi\n",
      "\n",
      "###\n",
      "\n",
      "Iona and i wanted to give you an update on travel both alonzo and mario are recommending against travel today reagan\n",
      "is still closed until this afternoon per alonzo.\n",
      "mario is holding seats on 7am tomorrow.\n",
      "as for trains, i talked to amtrak, they have trains running, some approx 1 hour behind schedule and a couple have\n",
      "canceled but they are running today.\n",
      "lona will be hearing from melanne in the next few hours or so about whether event will be on or canceled tomorrow.\n",
      "will keep you updated\n",
      "\n",
      "###\n",
      "\n",
      "Kurt campbell is asking if you would do a quick pull aside with Japanese Ambassador Fujisaki tomorrow. Kurt would do\n",
      "meeting, and would bring him by for a few minutes. Pls let me know what you think.\n",
      "Points he sent:\n",
      "\n",
      "###\n",
      "\n",
      "Thx.\n",
      "\n",
      "###\n",
      "\n",
      "FYI\n",
      "Forwarded messa e\n",
      "\n",
      "###\n",
      "\n",
      "Arlen Specter would like to speak to either of you regarding the possibility of the Syrians helping to free the\n",
      "three American hikers held by Iran. Thinks they can be helpful.\n"
     ]
    }
   ],
   "source": [
    "# print some examples\n",
    "print('\\n\\n###\\n\\n'.join(texts[3201:3207]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmpxRhaV_D2b"
   },
   "source": [
    "# 2. Data processing\n",
    "\n",
    "## Tokenizing with SoMaJo\n",
    "\n",
    "We can assume that every meme consists of one \"sentence\". To further split these into single words we have to tokenize the data.\n",
    "\n",
    "We can use the SoMaJo tokenizer which was developed especially for social media data and is easy to use.\n",
    "\n",
    "https://github.com/tsproisl/SoMaJo\n",
    "\n",
    "more info on the system: https://www.aclweb.org/anthology/W16-2607.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w5I-4DPBc4k",
    "outputId": "52115f71-6634-4883-eacd-dc411b6bfe6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SoMaJo\n",
      "  Downloading SoMaJo-2.2.1-py3-none-any.whl (90 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |███▋                            | 10 kB 20.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 20 kB 27.0 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 30 kB 21.6 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 40 kB 17.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 51 kB 8.8 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 61 kB 10.3 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 71 kB 9.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 81 kB 10.4 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 90 kB 5.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex>=2019.02.18 in /usr/local/lib/python3.7/dist-packages (from SoMaJo) (2019.12.20)\n",
      "Installing collected packages: SoMaJo\n",
      "Successfully installed SoMaJo-2.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install SoMaJo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "V2ICBAIdBo9l"
   },
   "outputs": [],
   "source": [
    "from somajo import SoMaJo\n",
    "\n",
    "somajo_tokenizer = SoMaJo(language=\"en_PTB\",\n",
    "                          split_camel_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "E-45d8AcCM9l"
   },
   "outputs": [],
   "source": [
    "# this might take a minute\n",
    "data_tok = []\n",
    "for sentence in somajo_tokenizer.tokenize_text(texts):\n",
    "    data_tok.append([token.text for token in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHC214XnAMkP",
    "outputId": "630df7e9-e9c5-476f-fecc-8c3257e60775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32290\n"
     ]
    }
   ],
   "source": [
    "print(len(data_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykl-epPuEU5T",
    "outputId": "d467dcdb-904c-48f4-d0f4-fc9e33ba1f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unfortunately', ',', 'the', 'European', 'Intelligence', 'services', 'have', 'been', 'unable', 'to', 'confirm', 'or', 'discredit', 'these', 'reports', '.']\n"
     ]
    }
   ],
   "source": [
    "print(data_tok[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc74x-tZ_LH0"
   },
   "source": [
    "# 3. Corpus statistics\n",
    "\n",
    "We will use the term \"frequency\" of a word type to express the absolute number of times this word occurs (in any context) in our corpus.\n",
    "\n",
    "Please note the terminological distinction:<br>\n",
    "**token**: Word form occuring in a text. The sentence \"This is it, is it?\" has 7 tokens \\['This', 'is', 'it', ',', 'is', 'it', '?'\\].<br>\n",
    "**type**: Unique word form in a text. The sentence \"This is it, is it?\" has 5 types {',', '?', 'This', 'is', 'it'}<br>\n",
    "A language/vocabulary consists of several word types; a corpus consists of tokens (which are mentions/occurrences of these types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "PFfJ4gYWL6Qs"
   },
   "outputs": [],
   "source": [
    "# count words and their frequencies\n",
    "from collections import Counter\n",
    "\n",
    "sentences = data_tok\n",
    "\n",
    "words = Counter(word for sentence in sentences for word in sentence)\n",
    "# Note: \"words\" now contains a mapping of words to their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4yNUCGoQMFIH",
    "outputId": "0cf8bb1a-a574-4922-ebf4-fae5f3500185"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of types (unique words): 37340\n",
      "Total number of tokens: 708310\n",
      "Number of types with frequency of occurrence 1: 17483\n",
      "Frequency of token \"man\": 105\n",
      "Frequency of token \"woman\": 74\n",
      "Frequency of token \"computing\": 1\n",
      "Frequency of token \"meaning\": 14\n",
      "Frequency of token \"!\": 556\n",
      "Frequency of token \"?\": 1968\n"
     ]
    }
   ],
   "source": [
    "# total number of types in the corpus\n",
    "print(f'Total number of types (unique words): {len(words)}')\n",
    "\n",
    "# total number of tokens in the corpus\n",
    "print(f'Total number of tokens: {sum(words.values())}')\n",
    "\n",
    "# how many words occur only once?\n",
    "print(f'Number of types with frequency of occurrence 1: {len([True for word in words if words[word] == 1])}')\n",
    "\n",
    "# show the frequency of some words\n",
    "for word in ('man', 'woman', 'computing', 'meaning', '!', '?'):\n",
    "    print(f'Frequency of token \"{word}\": {words[word]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHyrQuM5Mnoz",
    "outputId": "0cc32346-7a31-4ef8-cf63-333c97bef9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the most frequent words:\n",
      "[',', 'the', '.', 'to', 'and', 'of', 'a', 'in', '\"', 'that', \"'s\", 'is', 'for', '-', 'I', 'on', 'with', ':', 'you', 'it']\n",
      "\n",
      "some infrequent words:\n",
      "['hend', 'khe', 'rtzberq', '10/1', 'rooke', 'ntab', 'ixzz', 'HjNL4kn', 'DREAM', '•Thank']\n"
     ]
    }
   ],
   "source": [
    "sorted_words = sorted(words, key=lambda word: words[word], reverse=True)\n",
    "\n",
    "print('the most frequent words:')\n",
    "print(sorted_words[:20])\n",
    "\n",
    "print('\\nsome infrequent words:')\n",
    "print(sorted_words[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPgFbGDGQbBi"
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "### EXERCISE (see tasks at the end of the notebook) ###\n",
    "#######################################################\n",
    "\n",
    "# You should assign each word a rank according to the sorting by its frequency (i.e. the most \n",
    "# frequent word gets rank 1, the 2nd most frequent word gets rank 2, etc.).\n",
    "# The \"ranks\" dictionary should map each word to its frequency rank.\n",
    "ranks = {}\n",
    "\n",
    "# Assign each word rank the word frequency (i.e., for example, if the word on rank 10 (= the 10th \n",
    "# most frequent word) occurs 500 times, the resulting dictionary should map 10 to 500.) \n",
    "# The \"frequency_ranks\" dictionary should save a mapping from ranks to frequencies.\n",
    "frequency_ranks = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_pr3Gi8O3qg"
   },
   "source": [
    "# 4. Plotting Word Distribution\n",
    "\n",
    "Zipf's law states that: \\begin{equation}\\textit{occurrence_probability}(\\textit{word}) = \\frac{c}{\\text{rank}(\\textit{word})}\\end{equation}\n",
    "In other words: the occurrence probability of a word is inversely proportional to its frequency rank (with a corpus specific constant c).\n",
    "\n",
    "We can compute the occurrence probability of a word based on corpus data as follows:\n",
    "\\begin{equation}\n",
    "    \\textit{occurrence_probability}(\\textit{word}) = \\frac{\\textit{frequency of occurrence}(\\textit{word})}{\\textit{number of all words}}\n",
    "\\end{equation}\n",
    "For example, when a word occurs 20 times in a corpus of 100 tokens, its occurrence_probability is $0.2$.\n",
    "\n",
    "Above we calculated the frequency of occurrence of each word in our data. We now want to plot this value against the rank using Zipf's law and the formulae above.\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\textit{frequency of occurrence}(\\textit{word})}{\\textit{number of all words}} = \\frac{c}{\\text{rank}(\\textit{word})}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\textit{frequency of occurrence}(\\textit{word}) = \\frac{c * \\textit{number of all words}}{\\text{rank}(\\textit{word})}\n",
    "\\end{equation}\n",
    "\n",
    "Thus, if we want to plot the frequency on the y-axis, for any given rank $x$, the plot should display:\n",
    "\\begin{equation}\n",
    "f(x) = y = \\frac{c * \\textit{number of all words}}{x}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "9RAAfh2_O_R_",
    "outputId": "39d9f536-826b-44cb-909b-d4e2d71c72ee"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# set the constant c to some value for now\n",
    "c = 0.5\n",
    "\n",
    "# x-axis range:\n",
    "n_minimum = 3\n",
    "n_limit = 500\n",
    "\n",
    "# plot Zipf\n",
    "x_zipf = np.array(range(n_minimum, n_limit + 1))\n",
    "y_zipf = c * sum(words.values())/x_zipf  # this is the last formula above\n",
    "plt.plot(x_zipf, y_zipf, label='Zipf')\n",
    "# Note: this is what Zipf's law claims - we did not test it with our data yet.\n",
    "\n",
    "# here we plot the meme data (using the values from the cell above)\n",
    "if frequency_ranks:\n",
    "    lists = sorted(frequency_ranks.items())\n",
    "    x, y = zip(*lists)\n",
    "    plt.plot(x[n_minimum:n_limit], y[n_minimum:n_limit], label='Meme data')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLTI-vUSEE7E"
   },
   "source": [
    "#5. Collocations\n",
    "\n",
    "A collocation is \"a combination of words in a language that happens very often and more frequently than would happen by chance\".<br>\n",
    "These combinations are especially meaningful; there usually is a strong connection between the words; the words in combination often lead a new combined meaning; strong collocations can be considered lexical items.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRNa3XLGFkF3"
   },
   "source": [
    "## 5.1 Co-occuring word pairs\n",
    "\n",
    "We only have the frequencies of individual words so far.\n",
    "\n",
    "To compute collocation measure we need frequencies of co-occurring word pairs.\n",
    "\n",
    "For example, the tokenized sentence ['This', 'is', 'it', ',', 'is', 'it', '?']. has the following co-occuring word pairs:\n",
    "- ('This', 'is') frequency 1\n",
    "- ('is', 'it') frequency 2\n",
    "- ('it', ',') frequency 1\n",
    "- (',', 'is') frequency 1\n",
    "- ('it', '?') frequency 1\n",
    "\n",
    "Note that the sentence has 7 tokens, thus, 6 co-occurring word pairs (also known as bigrams), however, one of those occurs twice.\n",
    "\n",
    "We now count these for our entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "B_KZ-Cw2EEJs"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_word_pairs = Counter((word, sentence[index+1])\n",
    "                         for sentence in sentences\n",
    "                         for index, word in enumerate(sentence)\n",
    "                         if index+1 < len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1IjS4NYF5BC",
    "outputId": "41382612-f72d-47e2-e8c9-1eee34f0d3f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most frequent word pairs:\n",
      "[(('of', 'the'), 3295), (('in', 'the'), 2315), ((',', 'and'), 2132), ((',', 'the'), 1701), (('.', '\"'), 1436), (('to', 'the'), 1428), ((',', '\"'), 1396), (('on', 'the'), 1243), (('and', 'the'), 991), (('for', 'the'), 989)]\n",
      "\n",
      "The number of unique word pairs: 264046\n",
      "\n",
      "The number of unique word pairs with a frequency greater than 1:\n",
      "75505\n"
     ]
    }
   ],
   "source": [
    "# let us look at some\n",
    "print('The 10 most frequent word pairs:')\n",
    "print(sorted(all_word_pairs.items(), key=lambda pair: pair[1], reverse=True)[:10])\n",
    "\n",
    "print(f'\\nThe number of unique word pairs: {len(all_word_pairs)}')\n",
    "\n",
    "print('\\nThe number of unique word pairs with a frequency greater than 1:')\n",
    "print(len([pair for pair, frequency in all_word_pairs.items() if frequency > 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xq_UG2l-G0ds",
    "outputId": "5bf30131-c206-4420-99af-ba0ac1ac7222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of remaining word pairs: 4903\n"
     ]
    }
   ],
   "source": [
    "# to make it computationally feasible, only analyze word pairs with freq > some threshold\n",
    "# you might have to increase this value if running the cells in 5.2 take too long to finish\n",
    "threshold = 15\n",
    "word_pairs = {word_pair: frequency for word_pair, frequency in all_word_pairs.items() \n",
    "              if frequency >= threshold}\n",
    "print(f'number of remaining word pairs: {len(word_pairs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJJNyUdMHV9M"
   },
   "source": [
    "## 5.2 Collocation measures\n",
    "\n",
    "Above we actually used the most basic collocation measure: the frequency $o_{11}$ of the co-occurring word pair.\n",
    "\n",
    "Now we will compute the entire contingency table for each of the co-occuring word pairs (this might take a few seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "o_epuAMaHVn9"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "o11 = word_pairs\n",
    "o12 = defaultdict(int)\n",
    "o21 = defaultdict(int)\n",
    "o22 = defaultdict(int)\n",
    "\n",
    "for word_pair in word_pairs:\n",
    "    word1, word2 = word_pair\n",
    "    for other_word_pair in word_pairs:\n",
    "        other_word1, other_word2 = other_word_pair\n",
    "        if word1 == other_word1:\n",
    "            if word2 != other_word2:\n",
    "                o12[word_pair] += word_pairs[other_word_pair]\n",
    "            else:\n",
    "                # we already have this case in word_pairs\n",
    "                pass\n",
    "        else:\n",
    "            if word2 == other_word2:\n",
    "                o21[word_pair] += word_pairs[other_word_pair]\n",
    "            else:\n",
    "                o22[word_pair] += word_pairs[other_word_pair]\n",
    "\n",
    "# set min value to 1\n",
    "for pair in word_pair:\n",
    "    for cell in (o12, o21, o22):\n",
    "        if not cell[word_pair]:\n",
    "            cell[word_pair] = 1\n",
    "\n",
    "contingency_tables = {'o11': o11, 'o12': o12, 'o21': o21, 'o22': o22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "jJy5eIfuH1OU"
   },
   "outputs": [],
   "source": [
    "# A function to print highest ranked collocations, using a given collocation measure to compute ranking\n",
    "def print_highest_ranked_collocations(measure, top=10, tables=contingency_tables):\n",
    "    for pair in sorted(tables['o11'], key=lambda word_pair: measure(word_pair, tables), reverse=True)[:top]:\n",
    "        print((pair, tables['o11'][pair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvt0uQxgIQlS",
    "outputId": "40b3cf8a-4895-4e32-f1ce-73cf0f9feca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('of', 'the'), 3295)\n",
      "(('in', 'the'), 2315)\n",
      "((',', 'and'), 2132)\n",
      "((',', 'the'), 1701)\n",
      "(('.', '\"'), 1436)\n",
      "(('to', 'the'), 1428)\n",
      "((',', '\"'), 1396)\n",
      "(('on', 'the'), 1243)\n",
      "(('and', 'the'), 991)\n",
      "(('for', 'the'), 989)\n",
      "((',', 'but'), 839)\n",
      "(('to', 'be'), 772)\n",
      "(('that', 'the'), 736)\n",
      "(('with', 'the'), 712)\n",
      "(('Secretary', \"'s\"), 684)\n",
      "((',', 'a'), 645)\n",
      "(('at', 'the'), 636)\n",
      "((',', '2010'), 601)\n",
      "((',', '2009'), 575)\n",
      "(('is', 'a'), 568)\n",
      "(('will', 'be'), 552)\n",
      "(('of', 'State'), 505)\n",
      "(('as', 'a'), 501)\n",
      "((',', 'I'), 497)\n",
      "(('by', 'the'), 494)\n",
      "((\"'s\", 'Office'), 484)\n",
      "(('from', 'the'), 482)\n",
      "(('of', 'a'), 466)\n",
      "((',', 'which'), 454)\n",
      "(('No', '.'), 452)\n",
      "(('I', \"'m\"), 450)\n",
      "(('United', 'States'), 449)\n",
      "(('in', 'a'), 445)\n",
      "(('State', 'Department'), 442)\n",
      "(('is', 'the'), 420)\n",
      "(('White', 'House'), 415)\n",
      "((',', 'he'), 409)\n",
      "(('w', '/'), 407)\n",
      "((',', 'who'), 405)\n",
      "(('the', 'United'), 398)\n"
     ]
    }
   ],
   "source": [
    "def frequency(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    return pair_o11\n",
    "\n",
    "print_highest_ranked_collocations(frequency, top=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJUmsfc9H7gj",
    "outputId": "a839c2ca-911c-4959-8f4c-f51ada71462b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('CEREMONY', 'FOR'), 15)\n",
      "(('Foggy', 'Bottom'), 15)\n",
      "(('Jack', 'Lew'), 15)\n",
      "(('town', 'hall'), 15)\n",
      "(('WtBrn', 'Agn'), 15)\n",
      "(('Agn', 'Tot'), 15)\n",
      "(('Hamid', 'Karzai'), 15)\n",
      "(('Majority', 'Leader'), 15)\n",
      "(('European', 'Union'), 15)\n",
      "(('special', 'interests'), 15)\n",
      "(('abr', '='), 15)\n",
      "(('Nora', 'Toiv'), 16)\n",
      "(('Nancy', 'Pelosi'), 16)\n",
      "(('approval', 'rating'), 16)\n",
      "(('Jul', '7'), 16)\n",
      "(('Federal', 'Reserve'), 16)\n",
      "(('Joanne', 'Laszczych'), 16)\n",
      "(('Rahm', 'Emanuel'), 16)\n",
      "(('pharmaceutical', 'industry'), 16)\n",
      "(('OF', 'THE'), 17)\n",
      "(('Jimmy', 'Carter'), 17)\n",
      "(('hung', 'parliament'), 17)\n",
      "(('Brookings', 'Institution'), 17)\n",
      "(('Election', 'www.chathamhouse.org.uk'), 17)\n",
      "(('September', '12'), 18)\n",
      "(('Jim', 'Jones'), 18)\n",
      "(('Voting', 'Figures'), 18)\n",
      "(('Verizon', 'Wireless'), 19)\n",
      "(('Preliminary', 'Analysis'), 19)\n",
      "(('inner', 'circle'), 19)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# mutual information\n",
    "def mi(word_pair, tables):\n",
    "    pair_o11 = tables['o11'][word_pair]\n",
    "    pair_o12 = tables['o12'][word_pair]\n",
    "    pair_o21 = tables['o21'][word_pair]\n",
    "    pair_o22 = tables['o22'][word_pair]\n",
    "    \n",
    "    pair_R1 = pair_o11 + pair_o12\n",
    "    pair_C1 = pair_o11 + pair_o21\n",
    "    pair_N = pair_o11 + pair_o12 + pair_o21 + pair_o22\n",
    "    pair_e11 = pair_R1 * pair_C1 / float(pair_N)\n",
    "    \n",
    "    return math.log(pair_o11/pair_e11)\n",
    "\n",
    "print_highest_ranked_collocations(mi, top=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSoa6Rs8-79i"
   },
   "source": [
    "# 6. Exercises\n",
    "\n",
    "1.   Plotting your distribution\n",
    "\n",
    "    1.   Assign each word a rank according to the sorting by its frequency (i.e. the most frequent word gets rank 1, the 2nd most frequent word gets rank 2, etc.).\n",
    "\n",
    "    2.   Assign each word rank the word frequency (i.e., for example, if the word on rank 10 (= the 10th most frequent word) occurs 500 times, the resulting dictionary should map 10 to 500.) You should save the result in the variable 'frequency_ranks', see above.\n",
    "\n",
    "    3.   Plot your distribution together with Zipf's Law (if you defined the variable 'frequency_ranks' correctly, the code in 4. should do that). Modify the constant 'c' so the Zipf-plot fits to your data (approximately). You might also have to modify n_minimum and n_limit slightly so you can see it better.\n",
    "\n",
    "2.   Collocations\n",
    "\n",
    "    1.   Compare the number of unique word pairs to the number of unique words in our data. What do you observe? Is this expected? Why?\n",
    "    2.   Would you expect the distribution of unique word pairs also to follow Zipf’s law? Why (not)?\n",
    "    3.   Look at the top results extracted using the frequency measure. Do you think the definition of a collocation holds for these word pairs? Are these really collocations? Why (not)? What are issues when using just the frequency of word pairs as collocation measure?\n",
    "    4.   **(This is the main task of this exercise!)** Familiarize yourself with the language in this meme dataset. Write down 10 collocations for this data, i.e. pairs of words which you think are very strongly connected here (they do not really occur in other context and have a special meaning together). Implement a few (at least 5 in total) other collocation measures (http://collocations.de/AM/index.html). Which of these measures predicts the most of your 10 collocations in its top 100 results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTzvpnPA_C5S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NLP-2022_exercise3_statistics-collocations_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
